{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LyG7ZXYgFw7D"
   },
   "source": [
    "<h1>Transformer</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hcDbm3gnMe-9"
   },
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "oQ1mlzBQ60KN"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0MzFd5MHMgnO"
   },
   "source": [
    "# 스페인어-영어 말 묶음 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HTTP_PROXY\"] = \"70.10.15.10:8080\"\n",
    "os.environ['HTTPS_PROXY'] = \"70.10.15.10:8080\"\n",
    "os.environ['CURL_CA_BUNDLE'] = ''\n",
    "os.environ['PYTHONHTTPSVERIFY'] ='0' \n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Y_2CGsFdMcUB"
   },
   "outputs": [],
   "source": [
    "# 스페인어-영어 말 묶음 다운로드\n",
    "url ='http://www.manythings.org/anki/spa-eng.zip'\n",
    "filename = 'spa_eng.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zs9NFCbnMZOy"
   },
   "outputs": [],
   "source": [
    "# 강사가 별도로 파일을 제공했다면 이 셀은 실행하지 마세요.\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'\n",
    "}\n",
    "\n",
    "with open(filename, 'wb') as f:\n",
    "    r = requests.get(url, headers=headers)\n",
    "    f.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "JpXYjZWQMaLz"
   },
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "    zip_ref.extractall(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 574,
     "status": "ok",
     "timestamp": 1695558993287,
     "user": {
      "displayName": "bandal_lab이세우",
      "userId": "06927367528797360084"
     },
     "user_tz": -540
    },
    "id": "7eGn_2ZDWRh9",
    "outputId": "c9e4ad46-490d-4e9b-f191-3b70c445ed84",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>spa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Ve.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Vete.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Vaya.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Váyase.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Hola.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140863</th>\n",
       "      <td>A carbon footprint is the amount of carbon dio...</td>\n",
       "      <td>Una huella de carbono es la cantidad de contam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140864</th>\n",
       "      <td>Since there are usually multiple websites on a...</td>\n",
       "      <td>Como suele haber varias páginas web sobre cual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140865</th>\n",
       "      <td>If you want to sound like a native speaker, yo...</td>\n",
       "      <td>Si quieres sonar como un hablante nativo, debe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140866</th>\n",
       "      <td>It may be impossible to get a completely error...</td>\n",
       "      <td>Puede que sea imposible obtener un corpus comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140867</th>\n",
       "      <td>One day, I woke up to find that God had put ha...</td>\n",
       "      <td>Un día, me desperté y vi que Dios me había pue...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140868 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      eng  \\\n",
       "0                                                     Go.   \n",
       "1                                                     Go.   \n",
       "2                                                     Go.   \n",
       "3                                                     Go.   \n",
       "4                                                     Hi.   \n",
       "...                                                   ...   \n",
       "140863  A carbon footprint is the amount of carbon dio...   \n",
       "140864  Since there are usually multiple websites on a...   \n",
       "140865  If you want to sound like a native speaker, yo...   \n",
       "140866  It may be impossible to get a completely error...   \n",
       "140867  One day, I woke up to find that God had put ha...   \n",
       "\n",
       "                                                      spa  \n",
       "0                                                     Ve.  \n",
       "1                                                   Vete.  \n",
       "2                                                   Vaya.  \n",
       "3                                                 Váyase.  \n",
       "4                                                   Hola.  \n",
       "...                                                   ...  \n",
       "140863  Una huella de carbono es la cantidad de contam...  \n",
       "140864  Como suele haber varias páginas web sobre cual...  \n",
       "140865  Si quieres sonar como un hablante nativo, debe...  \n",
       "140866  Puede que sea imposible obtener un corpus comp...  \n",
       "140867  Un día, me desperté y vi que Dios me había pue...  \n",
       "\n",
       "[140868 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 영-스 병렬 말묶음 읽기\n",
    "# 0, 1번 열만 사용 (2번 열은 라이선스 정보)\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('spa.txt', names=['eng', 'spa'], sep='\\t', usecols=[0,1])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1695558993288,
     "user": {
      "displayName": "bandal_lab이세우",
      "userId": "06927367528797360084"
     },
     "user_tz": -540
    },
    "id": "BBldX61BWUTc",
    "outputId": "e402d9f2-dc94-45af-e15c-7361363bc183",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-432ca2d6-b59a-4f1c-bba0-7807b0041627\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>spa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Ve.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Vete.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Vaya.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Váyase.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Hola.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-432ca2d6-b59a-4f1c-bba0-7807b0041627')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-432ca2d6-b59a-4f1c-bba0-7807b0041627 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-432ca2d6-b59a-4f1c-bba0-7807b0041627');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-2c8b2cb6-a130-4fce-8e1e-df31a6d22542\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2c8b2cb6-a130-4fce-8e1e-df31a6d22542')\"\n",
       "            title=\"Suggest charts.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-2c8b2cb6-a130-4fce-8e1e-df31a6d22542 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   eng      spa\n",
       "0  Go.      Ve.\n",
       "1  Go.    Vete.\n",
       "2  Go.    Vaya.\n",
       "3  Go.  Váyase.\n",
       "4  Hi.    Hola."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = 50000 # 5만개 데이터를 학습\n",
    "train = df[:n_samples].copy()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xaveP7UjgI5R"
   },
   "source": [
    "## 텍스트 전처리\n",
    "* 액센트 기호 제거\n",
    "  * `unicodedata.normalize(form, unistr)` : unistr에 대한 정규화 형식\n",
    "    * 동일한 문제에 대해 다른 코드값 존재, 정규화 필요\n",
    "      * 예) 옴(Ω)와 오메가(Ω), 합자(é)\n",
    "    * form={'NFC', 'NFD', 'NFKC', 'NFKD'}\n",
    "  * `unicodedata.category(chr)` : 문자에 할당된 일반 범주\n",
    "    * 'Mn' : Mark nonspacing, 액센트 기호\n",
    "    * https://en.wikipedia.org/wiki/Template:General_Category_(Unicode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1695558993288,
     "user": {
      "displayName": "bandal_lab이세우",
      "userId": "06927367528797360084"
     },
     "user_tz": -540
    },
    "id": "fn1tlO3KWXgv",
    "outputId": "c983df32-04e3-4c6a-895a-7e032e423f5e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sé.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'S': 'Lu', 'e': 'Ll', '́': 'Mn', '.': 'Po'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unicodedata\n",
    "print(train['spa'][100])\n",
    "{c:unicodedata.category(c) for c in unicodedata.normalize('NFD', train['spa'][100])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1695558993288,
     "user": {
      "displayName": "bandal_lab이세우",
      "userId": "06927367528797360084"
     },
     "user_tz": -540
    },
    "id": "3ZKK9L6EWZZu",
    "outputId": "ba97c388-ebb0-495d-cefd-77d66f929a9d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제거 전: Inténtalo de nuevo.\n",
      "제거 후: Intentalo de nuevo.\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "# 액센트 기호 제거 함수\n",
    "def removeAccents(x):\n",
    "    char_list = []\n",
    "    for char in unicodedata.normalize('NFD', x):\n",
    "        if unicodedata.category(char) != 'Mn': # accent 기호\n",
    "            char_list.append(char)\n",
    "    return ''.join(char_list)\n",
    "\n",
    "print('제거 전:', train.loc[1109, 'spa'])\n",
    "print('제거 후:', removeAccents(train.loc[1109, 'spa']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "14WpTXWvWa7Z",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 전처리 함수 정의\n",
    "def text_preprocess(text):\n",
    "    # 액센트 기호 제거\n",
    "    text = removeAccents(text.lower())\n",
    "\n",
    "    # 알파벳 및 일부 기호(물음표, 느낌표, 마침표)를 제외한 문자 제거\n",
    "    text = re.sub(r'[^a-z0-9!.?]+', r' ', text)\n",
    "\n",
    "    # 기호와 단어 사이 공백 추가\n",
    "    text = re.sub(r'([?.!])', r' \\1', text)\n",
    "\n",
    "    # 연속 공백 제거\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1695558993289,
     "user": {
      "displayName": "bandal_lab이세우",
      "userId": "06927367528797360084"
     },
     "user_tz": -540
    },
    "id": "IDIGsUQZWc6H",
    "outputId": "a764fae9-f584-4208-83a8-49a81ad2776e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 문장 원본: \t Hold it.\n",
      "영어 문장 전처리: \t hold it .\n",
      "스페인어 문장 원본: \t Sosténgala.\n",
      "스페인어 문장 전처리: \t sostengala .\n"
     ]
    }
   ],
   "source": [
    "# 전처리 함수 동작 확인\n",
    "print('영어 문장 원본: \\t', train.loc[219, 'eng'].strip())\n",
    "print('영어 문장 전처리: \\t' ,text_preprocess(train.loc[219, 'eng']))\n",
    "print('스페인어 문장 원본: \\t', train.loc[219, 'spa'])\n",
    "print('스페인어 문장 전처리: \\t', text_preprocess(train.loc[219, 'spa']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FuHpBudMWedB",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 스페인어 인코더 입력 전처리\n",
    "words = train['spa'].apply(text_preprocess).str.split()\n",
    "spa_encoder_input_sentences = [word for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uzdFhlr9WgdT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 영어 디코더 입력/레이블 전처리\n",
    "eng_preprocessed_series = train['eng'].apply(text_preprocess)\n",
    "input_words = ('<sos> ' + eng_preprocessed_series).str.split()\n",
    "label_words = (eng_preprocessed_series + ' <eos>').str.split()\n",
    "\n",
    "eng_decoder_input_sentences = [word for word in input_words]\n",
    "eng_decoder_label_sentences = [word for word in label_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1695558995521,
     "user": {
      "displayName": "bandal_lab이세우",
      "userId": "06927367528797360084"
     },
     "user_tz": -540
    },
    "id": "cPvzvcNkWhpZ",
    "outputId": "1ca88234-3009-4cc7-c613-37aac4634f4c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Inputs:  [['ve', '.'], ['vete', '.'], ['vaya', '.']]\n",
      "Decoder Inputs:  [['<sos>', 'go', '.'], ['<sos>', 'go', '.'], ['<sos>', 'go', '.']]\n",
      "Decoder Labels:  [['go', '.', '<eos>'], ['go', '.', '<eos>'], ['go', '.', '<eos>']]\n"
     ]
    }
   ],
   "source": [
    "# 전처리된 문장 확인\n",
    "print('Encoder Inputs: ', spa_encoder_input_sentences[:3])\n",
    "print('Decoder Inputs: ', eng_decoder_input_sentences[:3])\n",
    "print('Decoder Labels: ', eng_decoder_label_sentences[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l87iQ2xNkw3N"
   },
   "source": [
    "## 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2b4qSgkXk5sK"
   },
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def token_generator(data):\n",
    "    for x in data:\n",
    "        yield x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 371,
     "status": "ok",
     "timestamp": 1695559002636,
     "user": {
      "displayName": "bandal_lab이세우",
      "userId": "06927367528797360084"
     },
     "user_tz": -540
    },
    "id": "u2kbXNqrXT_U",
    "outputId": "20d8064a-8a82-479d-d64b-6fcb052d6a84",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12933"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 스페인어 토큰화\n",
    "vocab_spa_torch = build_vocab_from_iterator(\n",
    "    iterator=token_generator(spa_encoder_input_sentences),\n",
    "    specials=['<PAD>', '<OOV>'])\n",
    "vocab_spa_torch.set_default_index(vocab_spa_torch['<OOV>'])\n",
    "len(vocab_spa_torch.get_stoi())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 369,
     "status": "ok",
     "timestamp": 1695559003003,
     "user": {
      "displayName": "bandal_lab이세우",
      "userId": "06927367528797360084"
     },
     "user_tz": -540
    },
    "id": "Jt59tWn7Z4XF",
    "outputId": "ce2063ea-66d5-4874-81b5-b23a2c1f7397",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6659"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 영어 토큰화\n",
    "vocab_eng_torch = build_vocab_from_iterator(\n",
    "    iterator=token_generator(eng_decoder_input_sentences+eng_decoder_label_sentences),\n",
    "    specials=['<PAD>', '<OOV>'])\n",
    "vocab_eng_torch.set_default_index(vocab_eng_torch['<OOV>'])\n",
    "len(vocab_eng_torch.get_stoi())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evfUetFRk_B2"
   },
   "source": [
    "## Text to Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wEhY-D0VaYc7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sent2seq_spa(sentences):\n",
    "    ret = []\n",
    "    for sentence in sentences:\n",
    "        seq = [vocab_spa_torch[token] for token in sentence]\n",
    "        ret.append(seq)\n",
    "    return ret\n",
    "\n",
    "def sent2seq_eng(sentences):\n",
    "    ret = []\n",
    "    for sentence in sentences:\n",
    "        seq = [vocab_eng_torch[token] for token in sentence]\n",
    "        ret.append(seq)\n",
    "    return ret\n",
    "\n",
    "encoder_inputs_torch = sent2seq_spa(spa_encoder_input_sentences)\n",
    "decoder_inputs_torch = sent2seq_eng(eng_decoder_input_sentences)\n",
    "decoder_labels_torch = sent2seq_eng(eng_decoder_label_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1695559004889,
     "user": {
      "displayName": "bandal_lab이세우",
      "userId": "06927367528797360084"
     },
     "user_tz": -540
    },
    "id": "wtvgWpaRd-bO",
    "outputId": "9a968bb2-8020-446a-97b5-509211dbfbe6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder 입력 길이: 13\n",
      "Decoder 입력 길이: 10\n",
      "Decoder 정답 길이: 10\n"
     ]
    }
   ],
   "source": [
    "# 입력 문장 최대 길이 확인\n",
    "encoder_input_len_torch = max([len(i) for i in encoder_inputs_torch])\n",
    "decoder_input_len_torch = max([len(i) for i in decoder_inputs_torch])\n",
    "decoder_label_len_torch = max([len(i) for i in decoder_labels_torch])\n",
    "print('Encoder 입력 길이:', encoder_input_len_torch)\n",
    "print('Decoder 입력 길이:', decoder_input_len_torch)\n",
    "print('Decoder 정답 길이:', decoder_label_len_torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4YyAShR9lIUG"
   },
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5CMQ9Xc-fYC5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "encoder_inputs_torch = [torch.LongTensor(seq[::-1]) for seq in encoder_inputs_torch] # pre\n",
    "decoder_inputs_torch = [torch.LongTensor(seq) for seq in decoder_inputs_torch] # post\n",
    "decoder_labels_torch = [torch.LongTensor(seq) for seq in decoder_labels_torch] # post\n",
    "\n",
    "encoder_inputs_torch = pad_sequence(encoder_inputs_torch,\n",
    "                               padding_value=vocab_spa_torch['<PAD>'], batch_first=True)\n",
    "decoder_inputs_torch = pad_sequence(decoder_inputs_torch,\n",
    "                               padding_value=vocab_eng_torch['<PAD>'], batch_first=True)\n",
    "decoder_labels_torch = pad_sequence(decoder_labels_torch,\n",
    "                               padding_value=vocab_eng_torch['<PAD>'], batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1695559008918,
     "user": {
      "displayName": "bandal_lab이세우",
      "userId": "06927367528797360084"
     },
     "user_tz": -540
    },
    "id": "_ACaVSwFfl9s",
    "outputId": "30e23415-d773-4fbf-9b63-174f3207f02a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder 입력: torch.Size([50000, 13])\n",
      "Decoder 입력: torch.Size([50000, 10])\n",
      "Decoder 정답: torch.Size([50000, 10])\n"
     ]
    }
   ],
   "source": [
    "# 데이터 shape 확인\n",
    "print('Encoder 입력:', encoder_inputs_torch.shape)\n",
    "print('Decoder 입력:', decoder_inputs_torch.shape)\n",
    "print('Decoder 정답:', decoder_labels_torch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1695559008919,
     "user": {
      "displayName": "bandal_lab이세우",
      "userId": "06927367528797360084"
     },
     "user_tz": -540
    },
    "id": "lIqg-Aeinq2u",
    "outputId": "781a04d1-c168-4cab-d319-cc820c4deaee",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    0,    0,  ...,    0,  173,    2],\n",
       "        [   0,    0,    0,  ...,    0,  509,    2],\n",
       "        [   0,    0,    0,  ...,    0,  558,    2],\n",
       "        ...,\n",
       "        [   0,    0,    0,  ..., 1261,  694,    2],\n",
       "        [   0,    0,    0,  ...,  177, 1227,    2],\n",
       "        [   0,    0,    0,  ..., 1203, 3523,    2]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_inputs_torch = torch.flip(encoder_inputs_torch, dims=(1,))\n",
    "encoder_inputs_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1695559009252,
     "user": {
      "displayName": "bandal_lab이세우",
      "userId": "06927367528797360084"
     },
     "user_tz": -540
    },
    "id": "uFvYHnZBpBqT",
    "outputId": "360d13a9-8329-4b87-bdcd-e6ddc83c8af6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder 입력: torch.Size([50000, 13])\n",
      "Decoder 입력: torch.Size([50000, 10])\n",
      "Decoder 정답: torch.Size([50000, 10])\n"
     ]
    }
   ],
   "source": [
    "# 데이터 shape 확인\n",
    "print('Encoder 입력:', encoder_inputs_torch.shape)\n",
    "print('Decoder 입력:', decoder_inputs_torch.shape)\n",
    "print('Decoder 정답:', decoder_labels_torch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZLpO0T7lQAE"
   },
   "source": [
    "## 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eLjA9dxvpDHH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 데이터 셔플\n",
    "import numpy as np\n",
    "\n",
    "n_samples = 50000\n",
    "\n",
    "np.random.seed(1)\n",
    "idx = np.arange(n_samples)\n",
    "np.random.shuffle(idx)\n",
    "encoder_inputs_torch = encoder_inputs_torch[idx]\n",
    "decoder_inputs_torch = decoder_inputs_torch[idx]\n",
    "decoder_labels_torch = decoder_labels_torch[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E38sQAJ8pjmu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 데이터 분할\n",
    "n_test_samples = int(n_samples*.2) # 8:2 분할\n",
    "encoder_inputs_train_torch = encoder_inputs_torch[:-n_test_samples]\n",
    "decoder_inputs_train_torch = decoder_inputs_torch[:-n_test_samples]\n",
    "decoder_labels_train_torch = decoder_labels_torch[:-n_test_samples]\n",
    "\n",
    "encoder_inputs_test_torch = encoder_inputs_torch[-n_test_samples:]\n",
    "decoder_inputs_test_torch = decoder_inputs_torch[-n_test_samples:]\n",
    "decoder_labels_test_torch = decoder_labels_torch[-n_test_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1695559009252,
     "user": {
      "displayName": "bandal_lab이세우",
      "userId": "06927367528797360084"
     },
     "user_tz": -540
    },
    "id": "UPKRWEOLp2MZ",
    "outputId": "06be274d-c07f-4832-deba-513833140da6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 Encoder 입력 크기: torch.Size([40000, 13])\n",
      "학습 Decoder 입력 크기: torch.Size([40000, 10])\n",
      "학습 Decoder 정답 크기: torch.Size([40000, 10])\n",
      "\n",
      "평가 Encoder 입력 크기: torch.Size([10000, 13])\n",
      "평가 Decoder 입력 크기: torch.Size([10000, 10])\n",
      "평가 Decoder 정답 크기: torch.Size([10000, 10])\n"
     ]
    }
   ],
   "source": [
    "print('학습 Encoder 입력 크기:', encoder_inputs_train_torch.shape)\n",
    "print('학습 Decoder 입력 크기:', decoder_inputs_train_torch.shape)\n",
    "print('학습 Decoder 정답 크기:', decoder_labels_train_torch.shape)\n",
    "print()\n",
    "print('평가 Encoder 입력 크기:', encoder_inputs_test_torch.shape)\n",
    "print('평가 Decoder 입력 크기:', decoder_inputs_test_torch.shape)\n",
    "print('평가 Decoder 정답 크기:', decoder_labels_test_torch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q0MMFw2klTmU"
   },
   "source": [
    "# Seq2Seq 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Ewc-4OgsnHM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_7-g0FqPraJN",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Encoder 구현\n",
    "class LSTMEncoder(nn.Module):\n",
    "    def __init__(self, hidden_size, embed_dim, enc_vocab_size, num_layers=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed = nn.Embedding(enc_vocab_size, embed_dim, padding_idx=0)\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embed_dim, hidden_size=hidden_size,\n",
    "            num_layers=num_layers, batch_first=True)\n",
    "\n",
    "        # 파라미터 초기화\n",
    "        nn.init.xavier_uniform_(next(self.lstm.parameters()))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.embed(x)\n",
    "        out, (hidden, cell) = self.lstm(out)\n",
    "\n",
    "        return out, hidden, cell # Decode에 전달할 hidden, cell state도 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x9cOmPlUYTIb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Decoder 구현\n",
    "class LSTMDecoder(nn.Module):\n",
    "    def __init__(self, hidden_size, embed_dim, dec_vocab_size, num_layers=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed = nn.Embedding(dec_vocab_size, embed_dim, padding_idx=0)\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embed_dim, hidden_size=hidden_size,\n",
    "            num_layers=num_layers, batch_first=True)\n",
    "\n",
    "        self.fc1 = nn.Linear(hidden_size, dec_vocab_size)\n",
    "\n",
    "        nn.init.xavier_uniform_(next(self.lstm.parameters()))\n",
    "        nn.init.xavier_uniform_(self.fc1.weight)\n",
    "\n",
    "    def forward(self, x, h_state, c_state): # 이전 state 입력\n",
    "        out = self.embed(x)\n",
    "        out, (hidden, cell) = self.lstm(out, (h_state, c_state))\n",
    "        out = self.fc1(out)\n",
    "\n",
    "        return out, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XORhM4D5sUdj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Encoder-Decoder 모델 구현\n",
    "import random\n",
    "import time\n",
    "\n",
    "class LSTMEncoderDecoderModel(nn.Module):\n",
    "    def __init__(self, hidden_size, embed_dim, enc_vocab_size, dec_vocab_size,\n",
    "                 num_layers=1, tf_rate=0.5, start_token=4, device='cpu'):\n",
    "        super().__init__()\n",
    "        self.tf_rate = tf_rate\n",
    "        self.dec_vocab_size = dec_vocab_size\n",
    "        self.start_token=start_token\n",
    "        self.device=device\n",
    "\n",
    "        self.encoder = LSTMEncoder(hidden_size, embed_dim, enc_vocab_size, num_layers)\n",
    "        self.decoder = LSTMDecoder(hidden_size, embed_dim, dec_vocab_size, num_layers)\n",
    "\n",
    "    def forward(self, x_input, y_targets):\n",
    "        # 출력 값을 저장할 텐서 생성\n",
    "        outputs = torch.zeros(x_input.shape[0], y_targets.shape[1],\n",
    "                              self.dec_vocab_size, device=torch.device(self.device))\n",
    "\n",
    "        # 인코드 출력 중 hidden state를 decoder 입력 state로 사용\n",
    "        out, hidden, cell = self.encoder(x_input)\n",
    "\n",
    "        # <'sos'> 토큰 입력\n",
    "        input_words = [self.start_token]*x_input.shape[0]\n",
    "        decoder_input = torch.LongTensor(input_words).reshape(-1, 1).to(device)\n",
    "\n",
    "        for t in range(y_targets.shape[1]):\n",
    "            out, hidden, cell = self.decoder(decoder_input, hidden, cell)\n",
    "\n",
    "            # 교사강요\n",
    "            if random.random() < self.tf_rate:\n",
    "                decoder_input = y_targets[:, t].unsqueeze(-1)\n",
    "            else:\n",
    "                decoder_input = out.argmax(dim=2) # (batch, 1, vocab_size)\n",
    "            outputs[:, t, :] = out.view(-1, self.dec_vocab_size)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QDWw1y3HKLRd"
   },
   "source": [
    "## Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l89tegList53",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, enc_x, dec_x, dec_y):\n",
    "        self.enc_x = enc_x\n",
    "        self.dec_x = dec_x\n",
    "        self.dec_y = dec_y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.enc_x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.enc_x[idx], self.dec_x[idx], self.dec_y[idx]\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "train_set = CustomDataset(encoder_inputs_train_torch,\n",
    "                          decoder_inputs_train_torch, decoder_labels_train_torch)\n",
    "test_set = CustomDataset(encoder_inputs_test_torch,\n",
    "                         decoder_inputs_test_torch, decoder_labels_test_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M06geCLgRVOg",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "SEED = 777\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=128,\n",
    "                          shuffle=True, drop_last=True)\n",
    "\n",
    "valid_loader = DataLoader(dataset=test_set, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rM6NNrQiM0be",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = LSTMEncoderDecoderModel(\n",
    "    64, 64, len(vocab_spa_torch.get_stoi()), len(vocab_eng_torch.get_stoi()),\n",
    "    tf_rate=1.0, device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19962,
     "status": "ok",
     "timestamp": 1695559042410,
     "user": {
      "displayName": "bandal_lab이세우",
      "userId": "06927367528797360084"
     },
     "user_tz": -540
    },
    "id": "tCsgh-rYLqm9",
    "outputId": "a3819cb7-54b5-4a0d-f707-2fc09c0b9b19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchinfo\n",
      "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: torchinfo\n",
      "Successfully installed torchinfo-1.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1695559042411,
     "user": {
      "displayName": "bandal_lab이세우",
      "userId": "06927367528797360084"
     },
     "user_tz": -540
    },
    "id": "VyA-RRZcMRUa",
    "outputId": "7fe1fb60-04fc-4331-de40-25672b242554"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "LSTMEncoderDecoderModel                  --\n",
       "├─LSTMEncoder: 1-1                       --\n",
       "│    └─Embedding: 2-1                    827,712\n",
       "│    └─LSTM: 2-2                         33,280\n",
       "├─LSTMDecoder: 1-2                       --\n",
       "│    └─Embedding: 2-3                    426,176\n",
       "│    └─LSTM: 2-4                         33,280\n",
       "│    └─Linear: 2-5                       432,835\n",
       "=================================================================\n",
       "Total params: 1,753,283\n",
       "Trainable params: 1,753,283\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7DL5ov0AKOky"
   },
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uAdje3ekP32b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_pad_token_idx = vocab_spa_torch.get_stoi()['<PAD>']\n",
    "loss = nn.CrossEntropyLoss(ignore_index=target_pad_token_idx).to(device)\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 258365,
     "status": "ok",
     "timestamp": 1695559301246,
     "user": {
      "displayName": "bandal_lab이세우",
      "userId": "06927367528797360084"
     },
     "user_tz": -540
    },
    "id": "GB_P-QAvMRUa",
    "outputId": "1c9c113a-7e35-47a4-a3b6-7e468ff4e1b8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [04:18<00:00,  5.16s/it, epoch=49, loss=0.62145, val_loss=1.94379]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "n_epochs = 50 # epochs 수\n",
    "\n",
    "results = {'Loss':[], 'Val_Loss':[]}\n",
    "\n",
    "pbar = tqdm(range(n_epochs))\n",
    "\n",
    "for epoch in pbar:\n",
    "    train_loss = 0\n",
    "    valid_loss = 0\n",
    "\n",
    "    n_train_batches = len(train_loader)\n",
    "    n_valid_batches = len(valid_loader)\n",
    "\n",
    "    model.train() # 학습 모드\n",
    "    for enc_x, dec_x, dec_y in train_loader:\n",
    "        enc_x, dec_x, dec_y = enc_x.to(device), dec_x.to(device), dec_y.to(device)\n",
    "        h = model(enc_x, dec_y) # 예측 값 생성\n",
    "        cost = loss(h.view(-1, h.shape[2]).to(device), dec_y.view(-1)) # cost 계산\n",
    "\n",
    "        optimizer.zero_grad() # 기울기 초기화\n",
    "        cost.backward()       # 역전파 수행\n",
    "        optimizer.step()      # 기울기 업데이트\n",
    "\n",
    "        train_loss += cost/n_train_batches\n",
    "    pbar.set_postfix(epoch=f'{epoch:2d}', loss=f'{train_loss.item():9.5f}')\n",
    "    results['Loss'].append(train_loss.item())\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for enc_x, dec_x, dec_y in valid_loader:\n",
    "            enc_x, dec_x, dec_y = enc_x.to(device), dec_x.to(device), dec_y.to(device)\n",
    "            h = model(enc_x, dec_y) # 예측 값 생성\n",
    "            cost = loss(h.view(-1, h.shape[2]).to(device), dec_y.view(-1)) # cost 계산\n",
    "\n",
    "            valid_loss += cost/n_valid_batches\n",
    "        pbar.set_postfix(epoch=f'{epoch:2d}',\n",
    "                         loss=f'{train_loss.item():9.5f}', val_loss=f'{valid_loss.item():9.5f}')\n",
    "        results['Val_Loss'].append(train_loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54IupoXLK8yg"
   },
   "source": [
    "## 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kMv0ANtxMRUb"
   },
   "outputs": [],
   "source": [
    "def predict(x_input, target_len=10):\n",
    "    # 출력 값을 저장할 텐서 생성\n",
    "    outputs = []\n",
    "\n",
    "    start_token = vocab_eng_torch.get_stoi()['<sos>']\n",
    "    eng_itos = vocab_eng_torch.get_itos()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # 인코드 출력 중 hidden state를 decoder 입력 state로 사용\n",
    "        out, hidden, cell = model.encoder(x_input)\n",
    "\n",
    "        # <'sos'> 토큰 입력\n",
    "        input_words = [start_token]*x_input.shape[0]\n",
    "        decoder_input = torch.LongTensor(input_words).reshape(-1, 1).to(device)\n",
    "\n",
    "        c_token = ''\n",
    "\n",
    "        for t in range(target_len):\n",
    "            out, hidden, cell = model.decoder(decoder_input, hidden, cell)\n",
    "            decoder_input = out.argmax(dim=2).reshape(-1, 1)\n",
    "            outputs.append(decoder_input.item())\n",
    "            c_token = eng_itos[outputs[-1]]\n",
    "            if c_token == '<eos>':\n",
    "                break\n",
    "    outputs = ' '.join([eng_itos[idx] for idx in outputs[:-1]])\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kwwF__jMMRUb"
   },
   "outputs": [],
   "source": [
    "def preprocessing(text, max_len=13):\n",
    "    seq = text_preprocess(text).split()\n",
    "    seq = ['<PAD>']*(max_len-len(seq))+seq\n",
    "    seq = sent2seq_spa([seq])\n",
    "    seq = torch.LongTensor(seq)\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1695559301247,
     "user": {
      "displayName": "bandal_lab이세우",
      "userId": "06927367528797360084"
     },
     "user_tz": -540
    },
    "id": "gKjTkArVJfx4",
    "outputId": "f168fc87-3d23-4bbf-ae96-f7590b0bbc50",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spanish: Tienen que ser más respetuosos.\n",
      "english: you must be more polite .\n"
     ]
    }
   ],
   "source": [
    "data = preprocessing(df.iloc[47855, 1]).to(device)\n",
    "pred = predict(data)\n",
    "print('spanish:', df.iloc[47855, 1])\n",
    "print('english:', pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1695559301247,
     "user": {
      "displayName": "bandal_lab이세우",
      "userId": "06927367528797360084"
     },
     "user_tz": -540
    },
    "id": "Ngcit0dXMRUb",
    "outputId": "5048edeb-5097-4d3d-8603-b49d6139e89d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spanish: ¿Es esto suficiente dinero?\n",
      "english: is this real silver ?\n"
     ]
    }
   ],
   "source": [
    "data = preprocessing(df.iloc[30402, 1]).to(device)\n",
    "pred = predict(data)\n",
    "print('spanish:', df.iloc[30402, 1])\n",
    "print('english:', pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dtLKsmohOZpS"
   },
   "source": [
    "# 기계번역 평가 지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KJWY7UyZXoSM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "spa_seq = 'La única habitación libre es una habitación doble.'\n",
    "eng_label_seq = 'The only room available is a double.'\n",
    "eng_predicted_seq = 'the only room is a light a lot of the weekend .'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FlsCHjxtOfFx"
   },
   "source": [
    "## Unigram Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 460,
     "status": "ok",
     "timestamp": 1695559589457,
     "user": {
      "displayName": "bandal_lab이세우",
      "userId": "06927367528797360084"
     },
     "user_tz": -540
    },
    "id": "7HfWCVoc6A5w",
    "outputId": "9da20f17-95ea-4dd6-fc0b-8f5b47594387",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Precision:  0.66667\n"
     ]
    }
   ],
   "source": [
    "# unigram precision\n",
    "import re\n",
    "\n",
    "predicted_text = re.sub(r'[^a-zA-Z0-9.]+', r' ', eng_predicted_seq)\n",
    "predicted_text = re.sub(r'([?.!])', r' \\1', predicted_text).strip().lower().split()\n",
    "label_text = re.sub(r'[^a-zA-Z0-9.]+', r' ', eng_label_seq)\n",
    "label_text = re.sub(r'([?.!])', r' \\1', label_text).strip().lower().split()\n",
    "\n",
    "n_total_pred = len(predicted_text)\n",
    "n_total_pred_in_label = 0\n",
    "\n",
    "for word in predicted_text:\n",
    "    if word in label_text:\n",
    "        n_total_pred_in_label+=1\n",
    "print(f'Unigram Precision: {n_total_pred_in_label/n_total_pred: .5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WX7lIGysOoW5"
   },
   "source": [
    "## Modified Unigram Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 357,
     "status": "ok",
     "timestamp": 1695559631696,
     "user": {
      "displayName": "bandal_lab이세우",
      "userId": "06927367528797360084"
     },
     "user_tz": -540
    },
    "id": "8D8EZDL36DJ9",
    "outputId": "73f65fed-76f7-4420-a4f9-d54a1082698f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Unigram Precision:  0.50000\n"
     ]
    }
   ],
   "source": [
    "# modified unigram precision\n",
    "predicted_text = re.sub(r'[^a-zA-Z0-9.]+', r' ', eng_predicted_seq)\n",
    "predicted_text = re.sub(r'([?.!])', r' \\1', predicted_text).strip().lower().split()\n",
    "label_text = re.sub(r'[^a-zA-Z0-9.]+', r' ', eng_label_seq)\n",
    "label_text = re.sub(r'([?.!])', r' \\1', label_text).strip().lower().split()\n",
    "\n",
    "n_total_pred = len(predicted_text)\n",
    "n_total_pred_in_label = 0\n",
    "\n",
    "for word in set(predicted_text):\n",
    "    n_total_pred_in_label+=label_text.count(word)\n",
    "print(f'Modified Unigram Precision: {n_total_pred_in_label/n_total_pred: .5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xo7HWGjgOuV-"
   },
   "source": [
    "## N-gram Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TCBiGS656GN7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# n-gram 데이터 생성 함수\n",
    "def convert_ngram(x, n):\n",
    "    ret = []\n",
    "    for i in range(len(x)-n+1):\n",
    "        ret.append(x[i:i+n])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1695559652557,
     "user": {
      "displayName": "bandal_lab이세우",
      "userId": "06927367528797360084"
     },
     "user_tz": -540
    },
    "id": "F9L7VWKk6H7T",
    "outputId": "dfcfaebf-efd6-43a2-9819-47fdd1df9fe0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-gram Precision:  0.27273\n"
     ]
    }
   ],
   "source": [
    "# n-gram precision\n",
    "def ngram_precision(label, pred, n):\n",
    "    predicted_ngram_text = convert_ngram(pred, n)\n",
    "    label_ngram_text = convert_ngram(label, n)\n",
    "\n",
    "    n_total_pred = len(predicted_ngram_text)\n",
    "    n_total_pred_in_label = 0\n",
    "\n",
    "    for ngram in set(tuple(i) for i in predicted_ngram_text):\n",
    "        n_total_pred_in_label+=label_ngram_text.count(list(ngram))\n",
    "    return n_total_pred_in_label/n_total_pred if n_total_pred>0 else 0\n",
    "print(f'N-gram Precision: {ngram_precision(label_text, predicted_text, 2): .5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8oGn74CmOyoI"
   },
   "source": [
    "## BLEU\n",
    "* Bilingual Evaluation Understudy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 623,
     "status": "ok",
     "timestamp": 1695559684528,
     "user": {
      "displayName": "bandal_lab이세우",
      "userId": "06927367528797360084"
     },
     "user_tz": -540
    },
    "id": "h5yW4MIu6KoR",
    "outputId": "92de1674-299f-4c63-dbbb-b16917521fc2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.34172334076593075\n"
     ]
    }
   ],
   "source": [
    "# BLEU 구현\n",
    "def BLEU(label, pred, weights=(.25, .25, .25)):\n",
    "    label_len = len(label)\n",
    "    pred_len = len(pred)\n",
    "\n",
    "    # Brevity Penalty\n",
    "    BP = 1 if pred_len>label_len else np.exp(1-(label_len/pred_len))\n",
    "\n",
    "    # n-gram precision 계산\n",
    "    n_precisions = np.array([ngram_precision(label, pred, n+1) for n in range(len(weights))])\n",
    "\n",
    "    # BLEU 계산\n",
    "    tol = 1e-300\n",
    "    n_precisions[n_precisions == 0] += tol\n",
    "    BLEU = BP * np.exp((np.log(n_precisions)*np.array(weights)).sum())\n",
    "    return BLEU\n",
    "print('BLEU Score:', BLEU(label_text, predicted_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oT32RgpTO9nW"
   },
   "source": [
    "# Attention Mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BoKNs-k8SlRZ"
   },
   "source": [
    "## Encoder, Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ojrXdijv6MIg",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Encoder 구현\n",
    "class LSTMEncoder(nn.Module):\n",
    "    def __init__(self, hidden_size, embed_dim, enc_vocab_size,\n",
    "                 num_layers=1, bidirectional=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed = nn.Embedding(enc_vocab_size, embed_dim)\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embed_dim, hidden_size=hidden_size,\n",
    "            num_layers=num_layers, batch_first=True, bidirectional=bidirectional)\n",
    "\n",
    "        # 파라미터 초기화\n",
    "        nn.init.xavier_uniform_(next(self.lstm.parameters()))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.embed(x)\n",
    "        out, (hidden, cell) = self.lstm(out)\n",
    "\n",
    "        return out, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ct76uSbt_PcX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Decoder 구현\n",
    "class LSTMDecoder(nn.Module):\n",
    "    def __init__(self, hidden_size, embed_dim, dec_vocab_size,\n",
    "                 num_layers=1, bidirectional=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed = nn.Embedding(dec_vocab_size, embed_dim)\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embed_dim, hidden_size=hidden_size,\n",
    "            num_layers=num_layers, batch_first=True, bidirectional=bidirectional)\n",
    "\n",
    "        nn.init.xavier_uniform_(next(self.lstm.parameters()))\n",
    "\n",
    "    def forward(self, x, states):\n",
    "        out = self.embed(x)\n",
    "        out, (hidden, cell) = self.lstm(out, states)\n",
    "\n",
    "        return out, hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z2NKAV1tSny8"
   },
   "source": [
    "## BahdanauAttension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t8ykvf55_SLv",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size, bidirectional=False):\n",
    "        super().__init__()\n",
    "\n",
    "        if bidirectional:\n",
    "            hidden_size = hidden_size*2\n",
    "\n",
    "        self.w_query = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "        self.w_key = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "        self.w_combined = nn.Linear(hidden_size, 1, bias=False)\n",
    "\n",
    "        nn.init.xavier_uniform_(self.w_query.weight)\n",
    "        nn.init.xavier_uniform_(self.w_key.weight)\n",
    "        nn.init.xavier_uniform_(self.w_combined.weight)\n",
    "\n",
    "    def forward(self, query, key, value=None):\n",
    "        if value == None:\n",
    "            value = key\n",
    "        out = torch.tanh(self.w_query(query) + self.w_key(key))\n",
    "        attention_score = self.w_combined(out).permute(0, 2, 1)\n",
    "        attention_weight = torch.softmax(attention_score, dim=2)\n",
    "        context_vector = torch.bmm(attention_weight, value)\n",
    "        return attention_score, attention_weight, context_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "efig7fmYSrdk"
   },
   "source": [
    "## LuongAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EMSQeycGBlbL",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def LuongAttention(query, key, value=None):\n",
    "    if value == None:\n",
    "        value = key\n",
    "    attention_score = torch.bmm(query, torch.transpose(key, 1,2))\n",
    "    attention_weight = torch.softmax(attention_score, dim=2)\n",
    "    context_vector = torch.bmm(attention_weight, value)\n",
    "    return attention_score, attention_weight, context_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-HSnZuHlSw9J"
   },
   "source": [
    "## AttentionModel 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "045uTtBSdGdS"
   },
   "outputs": [],
   "source": [
    "# Encoder-Decoder 모델 구현\n",
    "import random\n",
    "\n",
    "class AttentionModel(nn.Module):\n",
    "    def __init__(self, hidden_size, embed_dim, enc_vocab_size, dec_vocab_size,\n",
    "                 num_layers=1, tf_rate=0.5, bidirectional=False, device='cpu'):\n",
    "        super().__init__()\n",
    "        self.tf_rate = tf_rate\n",
    "        self.dec_vocab_size = dec_vocab_size\n",
    "        self.device = device\n",
    "\n",
    "        self.encoder = LSTMEncoder(hidden_size, embed_dim, enc_vocab_size,\n",
    "                                  num_layers, bidirectional=bidirectional)\n",
    "        self.decoder = LSTMDecoder(hidden_size, embed_dim, dec_vocab_size,\n",
    "                                  num_layers, bidirectional=bidirectional)\n",
    "\n",
    "        self.attention = BahdanauAttention(hidden_size, bidirectional=bidirectional)\n",
    "\n",
    "        if bidirectional:\n",
    "            self.output = nn.Linear(hidden_size*2*2, dec_vocab_size)\n",
    "        else:\n",
    "            self.output = nn.Linear(hidden_size*2, dec_vocab_size)\n",
    "\n",
    "        nn.init.xavier_uniform_(self.output.weight)\n",
    "\n",
    "    def forward(self, x_input, y_targets):\n",
    "        # 출력 값을 저장할 텐서 생성\n",
    "        outputs = torch.zeros(x_input.shape[0], y_targets.shape[1],\n",
    "                              self.dec_vocab_size, device=torch.device(self.device))\n",
    "\n",
    "        # 인코드 출력 중 hidden state를 decoder 입력 state로 사용\n",
    "        enc_out, hidden, cell= self.encoder(x_input)\n",
    "\n",
    "        # <'sos'> 토큰 입력\n",
    "        input_words = [vocab_eng_torch.get_stoi()['<sos>']]*x_input.shape[0]\n",
    "        decoder_input = torch.LongTensor(input_words).reshape(-1, 1).to(device)\n",
    "\n",
    "        for t in range(y_targets.shape[1]):\n",
    "            out, hidden, cell = self.decoder(decoder_input, (hidden, cell))\n",
    "\n",
    "            attention_score, attention_weight, context_vector = self.attention(out, enc_out)\n",
    "            out = torch.cat((context_vector, out), dim=2)\n",
    "            out = self.output(out)\n",
    "\n",
    "            # 교사강요\n",
    "            if random.random() < self.tf_rate:\n",
    "                decoder_input = y_targets[:, t].unsqueeze(-1)\n",
    "            else:\n",
    "                decoder_input = out.argmax(dim=2)\n",
    "            outputs[:, t, :] = out.view(-1, self.dec_vocab_size)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eKJkcodpS_h6"
   },
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GBF1LcelcIQi",
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(777)\n",
    "\n",
    "model = AttentionModel(\n",
    "    64, 64, len(vocab_spa_torch.get_stoi()),len(vocab_eng_torch.get_stoi()),\n",
    "    tf_rate=1.0, bidirectional=True, device=device).to(device)\n",
    "\n",
    "loss = nn.CrossEntropyLoss(ignore_index=target_pad_token_idx).to(device)\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 207102,
     "status": "ok",
     "timestamp": 1695563947902,
     "user": {
      "displayName": "bandal_lab이세우",
      "userId": "06927367528797360084"
     },
     "user_tz": -540
    },
    "id": "eTmPw2MaMRUf",
    "outputId": "dccee39d-0c98-4178-e3fb-b783a19c1e28"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [03:27<00:00, 10.35s/it, epoch=19, loss=0.31200, val_loss=1.31415]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "n_epochs = 20 # epochs 수\n",
    "\n",
    "results = {'Loss':[], 'Val_Loss':[]}\n",
    "\n",
    "pbar = tqdm(range(n_epochs))\n",
    "\n",
    "for epoch in pbar:\n",
    "    train_loss = 0\n",
    "    valid_loss = 0\n",
    "\n",
    "    n_train_batches = len(train_loader)\n",
    "    n_valid_batches = len(valid_loader)\n",
    "\n",
    "    model.train() # 학습 모드\n",
    "    for enc_x, dec_x, dec_y in train_loader:\n",
    "        enc_x, dec_x, dec_y = enc_x.to(device), dec_x.to(device), dec_y.to(device)\n",
    "        h = model(enc_x, dec_y) # 예측 값 생성\n",
    "        cost = loss(h.view(-1, h.shape[2]).to(device), dec_y.view(-1)) # cost 계산\n",
    "\n",
    "        optimizer.zero_grad() # 기울기 초기화\n",
    "        cost.backward()       # 역전파 수행\n",
    "        optimizer.step()      # 기울기 업데이트\n",
    "\n",
    "        train_loss += cost/n_train_batches\n",
    "    pbar.set_postfix(epoch=f'{epoch:2d}', loss=f'{train_loss.item():9.5f}')\n",
    "    results['Loss'].append(train_loss.item())\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for enc_x, dec_x, dec_y in valid_loader:\n",
    "            enc_x, dec_x, dec_y = enc_x.to(device), dec_x.to(device), dec_y.to(device)\n",
    "            h = model(enc_x, dec_y) # 예측 값 생성\n",
    "            cost = loss(h.view(-1, h.shape[2]).to(device), dec_y.view(-1)) # cost 계산\n",
    "\n",
    "            valid_loss += cost/n_valid_batches\n",
    "        pbar.set_postfix(epoch=f'{epoch:2d}',\n",
    "                         loss=f'{train_loss.item():9.5f}', val_loss=f'{valid_loss.item():9.5f}')\n",
    "        results['Val_Loss'].append(valid_loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ml_k9pxfTBXS"
   },
   "source": [
    "## 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vo61emKIMRUf"
   },
   "outputs": [],
   "source": [
    "def predict(x_input, target_len=10):\n",
    "    # 출력 값을 저장할 텐서 생성\n",
    "    outputs = []\n",
    "    weights = []\n",
    "\n",
    "    start_token = vocab_eng_torch.get_stoi()['<sos>']\n",
    "    eng_itos = vocab_eng_torch.get_itos()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # 인코드 출력 중 hidden state를 decoder 입력 state로 사용\n",
    "        enc_out, hidden, cell = model.encoder(x_input)\n",
    "\n",
    "        # <'sos'> 토큰 입력\n",
    "        input_words = [start_token]*x_input.shape[0]\n",
    "        decoder_input = torch.LongTensor(input_words).reshape(-1, 1).to(device)\n",
    "\n",
    "        c_token = ''\n",
    "\n",
    "        for t in range(target_len):\n",
    "            out, hidden, cell = model.decoder(decoder_input, (hidden, cell))\n",
    "            attention_score, attention_weight, context_vector = model.attention(out, enc_out)\n",
    "            out = torch.cat((context_vector, out), dim=2)\n",
    "            out = model.output(out)\n",
    "            decoder_input = out.argmax(dim=2).reshape(-1, 1)\n",
    "            outputs.append(decoder_input.item())\n",
    "            weights.append(attention_weight.reshape(-1).detach().cpu().numpy())\n",
    "            c_token = eng_itos[outputs[-1]]\n",
    "            if c_token == '<eos>':\n",
    "                break\n",
    "    outputs = ' '.join([eng_itos[idx] for idx in outputs[:-1]])\n",
    "    return outputs, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8PJM-Jlh6y1_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocessing(text, max_len=13):\n",
    "    seq = text_preprocess(text).split()\n",
    "    seq = ['<PAD>']*(max_len-len(seq))+seq\n",
    "    seq = sent2seq_spa([seq])\n",
    "    seq = torch.LongTensor(seq)\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1695563947904,
     "user": {
      "displayName": "bandal_lab이세우",
      "userId": "06927367528797360084"
     },
     "user_tz": -540
    },
    "id": "IkB8eN6Y6y1_",
    "outputId": "a70e1d51-d1ec-4a9b-b14f-75a0f177fe09",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spanish: Tienen que ser más respetuosos.\n",
      "english: you must be more polite .\n"
     ]
    }
   ],
   "source": [
    "data = preprocessing(df.iloc[47855, 1]).to(device)\n",
    "pred, weights= predict(data)\n",
    "print('spanish:', df.iloc[47855, 1])\n",
    "print('english:', pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1695563947904,
     "user": {
      "displayName": "bandal_lab이세우",
      "userId": "06927367528797360084"
     },
     "user_tz": -540
    },
    "id": "nrPtYQ-9MRUf",
    "outputId": "f4721a42-4dc2-49ee-dc76-506c3c1b9d83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spanish: ¿Es esto suficiente dinero?\n",
      "english: is this enough money ?\n"
     ]
    }
   ],
   "source": [
    "data = preprocessing(df.iloc[30402, 1]).to(device)\n",
    "pred, weights = predict(data)\n",
    "print('spanish:', df.iloc[30402, 1])\n",
    "print('english:', pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "executionInfo": {
     "elapsed": 1374,
     "status": "ok",
     "timestamp": 1695563949274,
     "user": {
      "displayName": "bandal_lab이세우",
      "userId": "06927367528797360084"
     },
     "user_tz": -540
    },
    "id": "qwBMPUcjoV11",
    "outputId": "20c220c9-e79f-45f6-fb10-0d67b38f7e11",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(np.array(weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wfXq5oa-huQX"
   },
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IUytrhzFlTih"
   },
   "source": [
    "## Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Okza5e16ZOY7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, position, d_embed, dropout, device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.pos_encoded = self.encode(position, d_embed).to(device)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def encode(self, length, depth): # 가산될 인코딩 값 계산 함수\n",
    "        positions = np.arange(length).reshape(-1, 1)\n",
    "\n",
    "        depth_even = np.arange(depth)[np.newaxis, ::2]*2/depth\n",
    "        depth_odd = np.arange(depth)[np.newaxis, 1::2]*2/depth\n",
    "\n",
    "        angle_rate_even = 1 / (10000**depth_even)\n",
    "        angle_rate_odd = 1 / (10000**depth_odd)\n",
    "\n",
    "        angle_rad_even = positions * angle_rate_even\n",
    "        angle_rad_odd = positions * angle_rate_odd\n",
    "\n",
    "        pos_encoding = np.zeros((length, depth))\n",
    "        pos_encoding[:, ::2] = np.sin(angle_rad_even)\n",
    "        pos_encoding[:, 1::2] = np.cos(angle_rad_odd)\n",
    "\n",
    "        return torch.FloatTensor(pos_encoding).unsqueeze(0)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        seq_len = inputs.shape[1]\n",
    "        out = self.dropout(inputs + self.pos_encoded[:, :seq_len, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TMd54buQGFCd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, seq_len, d_model, d_embed, vocab_size,\n",
    "                 dropout, pad, device):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, d_embed, padding_idx=pad)\n",
    "        self.positional_encoding = PositionalEncoding(seq_len, d_embed,\n",
    "                                                      dropout, device)\n",
    "        self.scaler = d_model**0.5\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        out = self.embed(inputs) * self.scaler\n",
    "        out = self.positional_encoding(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wSEUqLRKmpRh"
   },
   "source": [
    "## Multi-Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OKl8MLLCskHo",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, d_k):\n",
    "        super().__init__()\n",
    "        self.d_k = d_k\n",
    "        self.d_k_sqrt = self.d_k**(1/2)\n",
    "\n",
    "    def forward(self, query, key, value, padding_mask, causal_mask):\n",
    "        attention_score = torch.matmul(query, torch.transpose(key, -2, -1))/self.d_k_sqrt\n",
    "\n",
    "        if padding_mask is not None and causal_mask is not None:\n",
    "            mask = torch.maximum(causal_mask, padding_mask)\n",
    "            attention_score = attention_score.masked_fill(mask==1, -1e9)\n",
    "        elif padding_mask is not None:\n",
    "            attention_score = attention_score.masked_fill(padding_mask==1, -1e9)\n",
    "        elif causal_mask is not None:\n",
    "            attention_score = attention_score.masked_fill(causal_mask==1, -1e9)\n",
    "\n",
    "        attention_weight = torch.softmax(attention_score, dim=-1)\n",
    "        attention_value = torch.matmul(attention_weight, value)\n",
    "\n",
    "        return attention_score, attention_weight, attention_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SAQyJ3auVOud",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, d_embed, n_heads, device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.d_model = d_model\n",
    "        self.d_embed = d_embed\n",
    "        self.n_heads = n_heads\n",
    "        self.d_k = d_model // n_heads\n",
    "\n",
    "        self.w_q = nn.Linear(d_embed, d_model, bias=False)\n",
    "        self.w_k = nn.Linear(d_embed, d_model, bias=False)\n",
    "        self.w_v = nn.Linear(d_embed, d_model, bias=False)\n",
    "        self.w_0 = nn.Linear(d_model, d_embed, bias=False)\n",
    "\n",
    "        self.attention = ScaledDotProductAttention(self.d_k)\n",
    "\n",
    "        nn.init.kaiming_uniform_(self.w_q.weight)\n",
    "        nn.init.kaiming_uniform_(self.w_k.weight)\n",
    "        nn.init.kaiming_uniform_(self.w_v.weight)\n",
    "        nn.init.kaiming_uniform_(self.w_0.weight)\n",
    "\n",
    "    def forward(self, query, key, value=None, padding_mask=None, use_causal_mask=False):\n",
    "        if value is None:\n",
    "            value = key\n",
    "\n",
    "        wq = self.w_q(query)\n",
    "        wk = self.w_k(key)\n",
    "        wv = self.w_v(value)\n",
    "\n",
    "        wq = wq.view(wq.shape[0], -1, self.n_heads, self.d_k).permute(0, 2, 1, 3)\n",
    "        wk = wk.view(wk.shape[0], -1, self.n_heads, self.d_k).permute(0, 2, 1, 3)\n",
    "        wv = wv.view(wv.shape[0], -1, self.n_heads, self.d_k).permute(0, 2, 1, 3)\n",
    "\n",
    "        if use_causal_mask:\n",
    "            causal_mask = self._get_causal_mask(wq)\n",
    "        else:\n",
    "            causal_mask = None\n",
    "\n",
    "        attention_score, attention_weight, attention_value = self.attention(\n",
    "            wq, wk, wv, padding_mask=padding_mask, causal_mask=causal_mask)\n",
    "\n",
    "        attention_value = attention_value.permute(0, 2, 1, 3)\n",
    "        out = self.w_0(attention_value.contiguous().view(\n",
    "            attention_value.shape[0], -1, self.d_model))\n",
    "\n",
    "        return out, attention_score, attention_weight, attention_value\n",
    "\n",
    "    def _get_causal_mask(self, x):\n",
    "        mask = torch.ones((x.shape[-2], x.shape[-2]),\n",
    "                          device=torch.device(self.device)).triu(diagonal=1)\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZvsMe95TryuJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionWiseFedForwardNeuralNetwork(nn.Module):\n",
    "    def __init__(self, d_embed, d_ff):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(d_embed, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_embed)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        nn.init.kaiming_uniform_(self.fc1.weight)\n",
    "        nn.init.kaiming_uniform_(self.fc2.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.fc1(x))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4NCmywMimzPD"
   },
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UQJRiCxCukwM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, d_model, d_embed, d_ff, n_heads, dropout, device):\n",
    "        super().__init__()\n",
    "        self.attention = MultiHeadAttention(d_model, d_embed, n_heads, device)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        self.layernorm1 = nn.LayerNorm(d_embed)\n",
    "        self.layernorm2 = nn.LayerNorm(d_embed)\n",
    "\n",
    "        self.fc = PositionWiseFedForwardNeuralNetwork(d_embed, d_ff)\n",
    "\n",
    "    def forward(self, x, padding_mask=None):\n",
    "        out, a, w, v = self.attention(x, x, padding_mask=padding_mask) # self attention\n",
    "        out = self.dropout(out) # dropout\n",
    "        out1 = self.layernorm1(x+out) # Residual Connection and Layer Normalization\n",
    "        out2 = self.fc(out1) # PWFFN\n",
    "        out2 = self.dropout(out2) # dropout\n",
    "        out = self.layernorm2(out1+out2) # Residual Connection and Layer Normalization\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GU6vUPKTm0nq"
   },
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "62ib0atc7Akz",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, d_model, d_embed, d_ff, n_heads, dropout, device):\n",
    "        super().__init__()\n",
    "        self.self_attention = MultiHeadAttention(d_model, d_embed, n_heads, device)\n",
    "        self.cross_attention = MultiHeadAttention(d_model, d_embed, n_heads, device)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        self.layernorm1 = nn.LayerNorm(d_embed)\n",
    "        self.layernorm2 = nn.LayerNorm(d_embed)\n",
    "        self.layernorm3 = nn.LayerNorm(d_embed)\n",
    "\n",
    "        self.fc = PositionWiseFedForwardNeuralNetwork(d_embed, d_ff)\n",
    "\n",
    "    def forward(self, x, enc_out, self_padding_mask=None, cross_padding_mask=None):\n",
    "        out, a, w, v = self.self_attention(x, x, # self attention\n",
    "                                           padding_mask=self_padding_mask, use_causal_mask=True)\n",
    "        out = self.dropout(out) # dropout\n",
    "        out1 = self.layernorm1(x+out) # Residual Connection and Layer Normalization\n",
    "        out2, a, w, v = self.cross_attention(out1, enc_out, # cross attention\n",
    "                                             padding_mask=cross_padding_mask)\n",
    "        out2 = self.dropout(out2) # dropout\n",
    "        out1 = self.layernorm2(out1+out2) # Residual Connection and Layer Normalization\n",
    "        out2 = self.fc(out1) # PWFFN\n",
    "        out2 = self.dropout(out2) # dropout\n",
    "        out = self.layernorm3(out1+out2) # Residual Connection and Layer Normalization\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7yqlkvGHPAAj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerEncoderBlock(nn.Module):\n",
    "    def __init__(self, vocab_size, seq_len, d_model, d_embed, d_ff,\n",
    "                 n_heads, dropout, n_layers, pad, device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.positional_embedding = PositionalEmbedding(seq_len, d_model, d_embed,\n",
    "                                                        vocab_size, dropout, pad, device)\n",
    "        self.encoders = nn.ModuleList()\n",
    "\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        for i in range(n_layers):\n",
    "            self.encoders.append(TransformerEncoder(d_model, d_embed, d_ff,\n",
    "                                                    n_heads, dropout, device))\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        out = self.positional_embedding(x)\n",
    "\n",
    "        for i in range(self.n_layers):\n",
    "            out = self.encoders[i](out, padding_mask=mask)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FVwZYR4ZdB2q",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerDecoderBlock(nn.Module):\n",
    "    def __init__(self, vocab_size, seq_len, d_model, d_embed, d_ff,\n",
    "                 n_heads, dropout, n_layers, pad, device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.positional_embedding = PositionalEmbedding(seq_len, d_model, d_embed,\n",
    "                                                        vocab_size, dropout, pad, device)\n",
    "        self.decoders = nn.ModuleList()\n",
    "\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        for i in range(n_layers):\n",
    "            self.decoders.append(TransformerDecoder(d_model, d_embed, d_ff,\n",
    "                                                    n_heads, dropout, device))\n",
    "\n",
    "    def forward(self, x, enc_out, self_mask=None, cross_mask=None):\n",
    "        out = self.positional_embedding(x)\n",
    "\n",
    "        for i in range(self.n_layers):\n",
    "            out = self.decoders[i](out, enc_out,\n",
    "                                   self_padding_mask=self_mask, cross_padding_mask=cross_mask)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C0YekH-FnEEY"
   },
   "source": [
    "## Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UXsyWMJakSAM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, enc_vocab_size, dec_vocab_size, enc_seq_len, dec_seq_len,\n",
    "                 d_model=128, d_embed=128, d_ff=256, n_heads=2, dropout=0.1,\n",
    "                 n_layers=2, pad=0, device='cpu'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        self.encoder_block = TransformerEncoderBlock(enc_vocab_size, enc_seq_len,\n",
    "                                                     d_model, d_embed, d_ff, n_heads,\n",
    "                                                     dropout, n_layers, pad, device)\n",
    "        self.decoder_block = TransformerDecoderBlock(dec_vocab_size, dec_seq_len,\n",
    "                                                     d_model, d_embed, d_ff, n_heads,\n",
    "                                                     dropout, n_layers, pad, device)\n",
    "\n",
    "        self.fc = nn.Linear(d_embed, dec_vocab_size)\n",
    "\n",
    "        nn.init.xavier_uniform_(self.fc.weight)\n",
    "\n",
    "    def forward(self, enc_input, dec_input, pad=0):\n",
    "        enc_self_padding_mask = self._get_qk_padding_mask(enc_input, enc_input, pad).to(self.device)\n",
    "        dec_self_padding_mask = self._get_qk_padding_mask(dec_input, dec_input, pad).to(self.device)\n",
    "        dec_cross_padding_mask = self._get_qk_padding_mask(dec_input, enc_input, pad).to(self.device)\n",
    "\n",
    "        enc_out = self.encoder_block(enc_input, enc_self_padding_mask)\n",
    "        dec_out = self.decoder_block(dec_input, enc_out, dec_self_padding_mask, dec_cross_padding_mask)\n",
    "\n",
    "        out = self.fc(dec_out)\n",
    "        return out\n",
    "\n",
    "    def _get_padding_mask(self, x, pad):\n",
    "        mask = (x==pad)\n",
    "        return mask.to(torch.int32)\n",
    "\n",
    "    def _get_qk_padding_mask(self, query, key, pad):\n",
    "        query_mask = self._get_padding_mask(query, pad)\n",
    "        key_mask = self._get_padding_mask(key, pad)\n",
    "\n",
    "        query_mask = query_mask.unsqueeze(1).unsqueeze(3)\n",
    "        key_mask = key_mask.unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "        query_mask = query_mask.repeat(1, 1, 1, key.shape[1])\n",
    "        key_mask = key_mask.repeat(1, 1, query.shape[1], 1)\n",
    "\n",
    "        mask = query_mask | key_mask\n",
    "\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I1ofdhA0MRUk"
   },
   "outputs": [],
   "source": [
    "enc_vocab_size = len(vocab_spa_torch.get_stoi())\n",
    "enc_seq_len = encoder_inputs_train_torch.shape[1]\n",
    "\n",
    "dec_vocab_size = len(vocab_eng_torch.get_stoi())\n",
    "dec_seq_len = decoder_inputs_train_torch.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-2h8vkY7nhJR"
   },
   "outputs": [],
   "source": [
    "# enc_vocab_size, dec_vocab_size, enc_seq_len, dec_seq_len, d_model=128, d_embed=128, d_ff=64, n_heads=2, dropout=0.1, n_layers=5\n",
    "model = Transformer(enc_vocab_size, dec_vocab_size, enc_seq_len, dec_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1695564659453,
     "user": {
      "displayName": "bandal_lab이세우",
      "userId": "06927367528797360084"
     },
     "user_tz": -540
    },
    "id": "vO4S1WZgccj9",
    "outputId": "8fb9f81c-6f6a-4882-c477-66bd52b8b79c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 64])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe = PositionalEncoding(16, 64, 0.0, device)\n",
    "data = pe.pos_encoded.squeeze(0).detach().cpu().numpy()\n",
    "pe.pos_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1695564659454,
     "user": {
      "displayName": "bandal_lab이세우",
      "userId": "06927367528797360084"
     },
     "user_tz": -540
    },
    "id": "GwgLPTDBchS7",
    "outputId": "21c5839e-0f16-40a3-d81e-cd151d54f3be"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(data, cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.ylabel('Position')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b1DzzR4odvdp",
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(777)\n",
    "\n",
    "enc_vocab_size = len(vocab_spa_torch.get_stoi())\n",
    "enc_seq_len = encoder_inputs_train_torch.shape[1]\n",
    "\n",
    "dec_vocab_size = len(vocab_eng_torch.get_stoi())\n",
    "dec_seq_len = decoder_inputs_train_torch.shape[1]\n",
    "\n",
    "model = Transformer(enc_vocab_size, dec_vocab_size,  enc_seq_len,  dec_seq_len,\n",
    "                    d_model=128, d_embed=128, d_ff=256, n_heads=4, dropout=0.1, n_layers=2,\n",
    "                    pad=target_pad_token_idx, device=device).to(device)\n",
    "loss = nn.CrossEntropyLoss(ignore_index=target_pad_token_idx).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1, eps=1e-9, betas=(0.9, 0.98))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1695564659454,
     "user": {
      "displayName": "bandal_lab이세우",
      "userId": "06927367528797360084"
     },
     "user_tz": -540
    },
    "id": "jlUcHTeUMRUm",
    "outputId": "df1694e1-1551-4a59-81d2-2c2360fdbeeb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                                            Param #\n",
       "==========================================================================================\n",
       "Transformer                                                       --\n",
       "├─TransformerEncoderBlock: 1-1                                    --\n",
       "│    └─PositionalEmbedding: 2-1                                   --\n",
       "│    │    └─Embedding: 3-1                                        1,655,424\n",
       "│    │    └─PositionalEncoding: 3-2                               --\n",
       "│    └─ModuleList: 2-2                                            --\n",
       "│    │    └─TransformerEncoder: 3-3                               131,968\n",
       "│    │    └─TransformerEncoder: 3-4                               131,968\n",
       "├─TransformerDecoderBlock: 1-2                                    --\n",
       "│    └─PositionalEmbedding: 2-3                                   --\n",
       "│    │    └─Embedding: 3-5                                        852,352\n",
       "│    │    └─PositionalEncoding: 3-6                               --\n",
       "│    └─ModuleList: 2-4                                            --\n",
       "│    │    └─TransformerDecoder: 3-7                               197,760\n",
       "│    │    └─TransformerDecoder: 3-8                               197,760\n",
       "├─Linear: 1-3                                                     859,011\n",
       "==========================================================================================\n",
       "Total params: 4,026,243\n",
       "Trainable params: 4,026,243\n",
       "Non-trainable params: 0\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2kAFfrt5nVPs"
   },
   "source": [
    "## Model 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JQaCwsV5MRUm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WarmupLRScheduler(optim.lr_scheduler.LambdaLR):\n",
    "    def __init__(self, optimizer, d_model,  warmup_steps, last_epoch=-1):\n",
    "        def lambda_lr(step):\n",
    "            arg1 = step**-0.5 if step > 0 else 0\n",
    "            arg2 = step * (warmup_steps ** -1.5)\n",
    "            return (d_model**-0.5) * min(arg1, arg2)\n",
    "        super().__init__(optimizer, lambda_lr, last_epoch=last_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1KncrRCwMRUm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "d_model=128\n",
    "warmup_steps=4000\n",
    "scheduler = WarmupLRScheduler(optimizer, d_model, warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ed4y7zecMRUm"
   },
   "outputs": [],
   "source": [
    "# values = []\n",
    "# for step in range(40000):\n",
    "#     arg1 = step**-0.5 if step > 0 else 0\n",
    "#     arg2 = step * (warmup_steps ** -1.5)\n",
    "#     values.append((d_model**-0.5) * min(arg1, arg2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "heCRnIFRMRUm"
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12, 5))\n",
    "# plt.plot(range(40000), values)\n",
    "# plt.xlabel('Train Step')\n",
    "# plt.ylabel('Learning Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 322609,
     "status": "ok",
     "timestamp": 1695564983504,
     "user": {
      "displayName": "bandal_lab이세우",
      "userId": "06927367528797360084"
     },
     "user_tz": -540
    },
    "id": "UQ_cTWwnMRUn",
    "outputId": "43c1007e-15be-4fc0-b6c3-b2b2931f49f1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [05:22<00:00,  6.45s/it, epoch=49, loss=0.46040, val_loss=1.24743]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "n_epochs = 50 # epochs 수\n",
    "\n",
    "results = {'Loss':[], 'Val_Loss':[]}\n",
    "\n",
    "pbar = tqdm(range(n_epochs))\n",
    "\n",
    "for epoch in pbar:\n",
    "    train_loss = 0\n",
    "    valid_loss = 0\n",
    "\n",
    "    n_train_batches = len(train_loader)\n",
    "    n_valid_batches = len(valid_loader)\n",
    "\n",
    "    model.train() # 학습 모드\n",
    "    for enc_x, dec_x, dec_y in train_loader:\n",
    "        enc_x, dec_x, dec_y = enc_x.to(device), dec_x.to(device), dec_y.to(device)\n",
    "        h = model(enc_x, dec_x) # 예측 값 생성\n",
    "        cost = loss(h.view(-1, h.shape[2]).to(device), dec_y.view(-1)) # cost 계산\n",
    "\n",
    "        optimizer.zero_grad() # 기울기 초기화\n",
    "        cost.backward()       # 역전파 수행\n",
    "        optimizer.step()      # 기울기 업데이트\n",
    "        scheduler.step()      # 학습률 업데이트\n",
    "\n",
    "        train_loss += cost/n_train_batches\n",
    "    pbar.set_postfix(epoch=f'{epoch:2d}', loss=f'{train_loss.item():9.5f}')\n",
    "    results['Loss'].append(train_loss.item())\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for enc_x, dec_x, dec_y in valid_loader:\n",
    "            enc_x, dec_x, dec_y = enc_x.to(device), dec_x.to(device), dec_y.to(device)\n",
    "            h = model(enc_x, dec_x) # 예측 값 생성\n",
    "            cost = loss(h.view(-1, h.shape[2]).to(device), dec_y.view(-1)) # cost 계산\n",
    "\n",
    "            valid_loss += cost/n_valid_batches\n",
    "        pbar.set_postfix(epoch=f'{epoch:2d}',\n",
    "                         loss=f'{train_loss.item():9.5f}', val_loss=f'{valid_loss.item():9.5f}')\n",
    "        results['Val_Loss'].append(valid_loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2cKCx6vrnYSL"
   },
   "source": [
    "## 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "frp5qaxbtWLc"
   },
   "outputs": [],
   "source": [
    "def predict(x_input, target_len=10):\n",
    "    outputs = []\n",
    "\n",
    "    start_token = vocab_eng_torch.get_stoi()['<sos>']\n",
    "    pad = vocab_eng_torch.get_stoi()['<PAD>']\n",
    "    eng_itos = vocab_eng_torch.get_itos()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_sequence = [start_token] + ([pad]*(target_len-1))\n",
    "        decoder_input = torch.LongTensor(input_sequence).reshape(1, -1).to(device)\n",
    "\n",
    "        for t in range(target_len):\n",
    "            out = model(x_input, decoder_input)\n",
    "            c_token = out[:, t, :].argmax(dim=1)\n",
    "            decoder_input[:, t+1] = c_token\n",
    "            word = eng_itos[c_token.item()]\n",
    "            if word == '<eos>':\n",
    "                break\n",
    "    outputs = ' '.join([eng_itos[idx] for idx in decoder_input.view(-1)[1:t+1]])\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1695564983506,
     "user": {
      "displayName": "bandal_lab이세우",
      "userId": "06927367528797360084"
     },
     "user_tz": -540
    },
    "id": "0MzNm5CxMRUn",
    "outputId": "4d73859a-c587-4d2d-bdcc-c5940b301794"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spanish: Tienen que ser más respetuosos.\n",
      "english: they must be more polite .\n"
     ]
    }
   ],
   "source": [
    "def preprocessing(text, max_len=13):\n",
    "    seq = text_preprocess(text).split()\n",
    "    seq = ['<PAD>']*(max_len-len(seq))+seq\n",
    "    seq = sent2seq_spa([seq])\n",
    "    seq = torch.LongTensor(seq)\n",
    "    return seq\n",
    "\n",
    "data = preprocessing(df.iloc[47855, 1]).to(device)\n",
    "pred = predict(data)\n",
    "print('spanish:', df.iloc[47855, 1])\n",
    "print('english:', pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1695564983506,
     "user": {
      "displayName": "bandal_lab이세우",
      "userId": "06927367528797360084"
     },
     "user_tz": -540
    },
    "id": "lFEHLN7WMRUn",
    "outputId": "0290fb51-0101-4070-f0ef-b8d2137094f8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spanish: ¿Es esto suficiente dinero?\n",
      "english: is this enough money ?\n"
     ]
    }
   ],
   "source": [
    "data = preprocessing(df.iloc[30402, 1]).to(device)\n",
    "pred = predict(data)\n",
    "print('spanish:', df.iloc[30402, 1])\n",
    "print('english:', pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eUZ7KIk-MRUo"
   },
   "source": [
    "# torch.nn.Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NpVqt-yPMRUo"
   },
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, enc_vocab_size, dec_vocab_size, enc_seq_len, dec_seq_len,\n",
    "                 d_model=128, d_embed=128, d_ff=256, n_heads=2, dropout=0.1,\n",
    "                 n_layers=2, pad=0, device='cpu'):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.pad = pad\n",
    "\n",
    "        self.enc_embed = PositionalEmbedding(enc_seq_len, d_model, d_embed, enc_vocab_size, dropout, pad, device)\n",
    "        self.dec_embed = PositionalEmbedding(dec_seq_len, d_model, d_embed, dec_vocab_size, dropout, pad, device)\n",
    "        self.transformer = nn.Transformer(d_model, n_heads, n_layers, n_layers,\n",
    "                                          d_ff, dropout, batch_first=True, device=torch.device(device))\n",
    "        self.fc = nn.Linear(d_model, dec_vocab_size)\n",
    "\n",
    "    def forward(self, encoder_input, decoder_input):\n",
    "        enc_out = self.enc_embed(encoder_input)\n",
    "        dec_out = self.dec_embed(decoder_input)\n",
    "\n",
    "        enc_padding_mask = (encoder_input == self.pad).to(self.device)\n",
    "        dec_padding_mask = (decoder_input == self.pad).to(self.device)\n",
    "        dec_mask = self.transformer.generate_square_subsequent_mask(decoder_input.size(1)).bool().to(self.device)\n",
    "        out = self.transformer(enc_out, dec_out,\n",
    "                               src_key_padding_mask=enc_padding_mask,\n",
    "                               tgt_key_padding_mask=dec_padding_mask,\n",
    "                               memory_key_padding_mask=enc_padding_mask, tgt_mask=dec_mask)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d-vwQ6hbMRUo"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(777)\n",
    "\n",
    "enc_vocab_size = len(vocab_spa_torch.get_stoi())\n",
    "enc_seq_len = encoder_inputs_train_torch.shape[1]\n",
    "\n",
    "dec_vocab_size = len(vocab_eng_torch.get_stoi())\n",
    "dec_seq_len = decoder_inputs_train_torch.shape[1]\n",
    "\n",
    "model = TransformerModel(enc_vocab_size, dec_vocab_size,  enc_seq_len,  dec_seq_len,\n",
    "                    d_model=128, d_embed=128, d_ff=256, n_heads=4, dropout=0.1, n_layers=2,\n",
    "                    pad=target_pad_token_idx, device=device).to(device)\n",
    "loss = nn.CrossEntropyLoss(ignore_index=target_pad_token_idx).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1, eps=1e-9, betas=(0.9, 0.98))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IJXO_qLKMRUo"
   },
   "outputs": [],
   "source": [
    "d_model=128\n",
    "warmup_steps=4000\n",
    "scheduler = WarmupLRScheduler(optimizer, d_model, warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 340907,
     "status": "ok",
     "timestamp": 1695565324406,
     "user": {
      "displayName": "bandal_lab이세우",
      "userId": "06927367528797360084"
     },
     "user_tz": -540
    },
    "id": "cDWYwCX1MRUo",
    "outputId": "25fd3717-2826-4389-bda3-0a6609923f24"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:06<?, ?it/s, epoch=0, loss=7.08868]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:562: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)\n",
      "  return torch._transformer_encoder_layer_fwd(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)\n",
      "  return torch._native_multi_head_attention(\n",
      "100%|██████████| 50/50 [05:40<00:00,  6.81s/it, epoch=49, loss=0.41200, val_loss=1.21330]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "n_epochs = 50 # epochs 수\n",
    "\n",
    "results = {'Loss':[], 'Val_Loss':[]}\n",
    "\n",
    "pbar = tqdm(range(n_epochs))\n",
    "\n",
    "for epoch in pbar:\n",
    "    train_loss = 0\n",
    "    valid_loss = 0\n",
    "\n",
    "    n_train_batches = len(train_loader)\n",
    "    n_valid_batches = len(valid_loader)\n",
    "\n",
    "    model.train() # 학습 모드\n",
    "    for enc_x, dec_x, dec_y in train_loader:\n",
    "        enc_x, dec_x, dec_y = enc_x.to(device), dec_x.to(device), dec_y.to(device)\n",
    "        h = model(enc_x, dec_x) # 예측 값 생성\n",
    "        cost = loss(h.view(-1, h.shape[2]).to(device), dec_y.view(-1)) # cost 계산\n",
    "\n",
    "        optimizer.zero_grad() # 기울기 초기화\n",
    "        cost.backward()       # 역전파 수행\n",
    "        optimizer.step()      # 기울기 업데이트\n",
    "        scheduler.step()      # 학습률 업데이트\n",
    "\n",
    "        train_loss += cost/n_train_batches\n",
    "    pbar.set_postfix(epoch=f'{epoch:2d}', loss=f'{train_loss.item():9.5f}')\n",
    "    results['Loss'].append(train_loss.item())\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for enc_x, dec_x, dec_y in valid_loader:\n",
    "            enc_x, dec_x, dec_y = enc_x.to(device), dec_x.to(device), dec_y.to(device)\n",
    "            h = model(enc_x, dec_x) # 예측 값 생성\n",
    "            cost = loss(h.view(-1, h.shape[2]).to(device), dec_y.view(-1)) # cost 계산\n",
    "\n",
    "            valid_loss += cost/n_valid_batches\n",
    "        pbar.set_postfix(epoch=f'{epoch:2d}',\n",
    "                         loss=f'{train_loss.item():9.5f}', val_loss=f'{valid_loss.item():9.5f}')\n",
    "        results['Val_Loss'].append(valid_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dn3JuFKKMRUy"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "instance_type": "ml.g4dn.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
